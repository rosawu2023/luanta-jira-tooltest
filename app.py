import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import timezone

# =========================================================
# Page config
# =========================================================
st.set_page_config(page_title="Luanta Jira Analytics", layout="wide")

# =========================================================
# Global CSS (Cards / spacing / typography)
# =========================================================
st.markdown(
    """
<style>
/* Make overall spacing calmer */
.block-container { padding-top: 1.2rem; padding-bottom: 2rem; }

/* Card container */
.section-card {
  border: 1px solid rgba(49, 51, 63, 0.12);
  background: rgba(255,255,255,0.70);
  border-radius: 14px;
  padding: 18px 18px 10px 18px;
  margin: 14px 0 18px 0;
}

/* Card header area */
.section-title {
  font-size: 1.25rem;
  font-weight: 700;
  margin: 0 0 0.15rem 0;
}
.section-subtitle {
  font-size: 0.92rem;
  opacity: 0.75;
  margin: 0 0 0.6rem 0;
}

/* Smaller note block */
.note {
  border-left: 4px solid rgba(0, 123, 255, 0.55);
  padding: 10px 12px;
  background: rgba(0, 123, 255, 0.06);
  border-radius: 10px;
  margin: 8px 0 10px 0;
}

/* Empty state block */
.empty {
  border-left: 4px solid rgba(255, 193, 7, 0.70);
  padding: 10px 12px;
  background: rgba(255, 193, 7, 0.10);
  border-radius: 10px;
  margin: 8px 0 10px 0;
}

/* Divider line between subparts */
.soft-divider {
  height: 1px;
  background: rgba(49, 51, 63, 0.10);
  margin: 12px 0 12px 0;
}

/* Reduce chart title noise */
h3 { margin-top: 0.5rem !important; }

/* Sidebar spacing */
section[data-testid="stSidebar"] .block-container { padding-top: 1rem; }
</style>
""",
    unsafe_allow_html=True,
)

# =========================================================
# Language toggle
# =========================================================
LANG_OPTIONS = {
    "ä¸­æ–‡": "zh",
    "English": "en",
    "é›™èª": "bi",
}

st.sidebar.header("Settings")
lang_label = st.sidebar.radio("Language / èªè¨€", list(LANG_OPTIONS.keys()), index=0)
LANG = LANG_OPTIONS[lang_label]


def tx(en: str, zh: str) -> str:
    """Return text in selected language. No parentheses. Bilingual shown as two lines."""
    if LANG == "zh":
        return zh
    if LANG == "en":
        return en
    # bilingual
    return f"{en}\n{zh}"


def card_title(en: str, zh: str, subtitle_en: str = "", subtitle_zh: str = ""):
    st.markdown(
        f"""
<div class="section-title">{tx(en, zh).replace("\n","<br/>")}</div>
<div class="section-subtitle">{tx(subtitle_en, subtitle_zh).replace("\n","<br/>")}</div>
""",
        unsafe_allow_html=True,
    )


def note(en: str, zh: str):
    st.markdown(
        f"""<div class="note">{tx(en, zh).replace("\n","<br/>")}</div>""",
        unsafe_allow_html=True,
    )


def empty_state(en: str, zh: str, tips=None):
    st.markdown(
        f"""<div class="empty">{tx(en, zh).replace("\n","<br/>")}</div>""",
        unsafe_allow_html=True,
    )
    if tips:
        with st.expander(tx("Possible reasons / Troubleshooting", "å¯èƒ½åŸå›  / æ’æŸ¥å»ºè­°"), expanded=False):
            for x in tips:
                st.write(f"- {x}")


def render_chart_or_empty(df_plot: pd.DataFrame, chart_fn, empty_en: str, empty_zh: str, tips=None):
    if df_plot is None or df_plot.empty:
        empty_state(empty_en, empty_zh, tips=tips)
        return
    fig = chart_fn(df_plot)
    st.plotly_chart(fig, use_container_width=True)


def safe_first_match(cols, keyword_list):
    """Return first column that contains any keyword (case-insensitive)."""
    for kw in keyword_list:
        for c in cols:
            if kw.lower() in c.lower():
                return c
    return None


def to_datetime_safe(s):
    return pd.to_datetime(s, errors="coerce", utc=True)


# =========================================================
# Title
# =========================================================
st.title("ğŸ“Š " + tx("Luanta Service Performance Dashboard", "Luanta æœå‹™ç¸¾æ•ˆå„€è¡¨æ¿"))

# =========================================================
# Sidebar - Upload
# =========================================================
st.sidebar.header(tx("Step 1: Upload Data", "æ­¥é©Ÿ 1ï¼šä¸Šå‚³è³‡æ–™"))
uploaded_file = st.sidebar.file_uploader(tx("Upload Jira CSV", "ä¸Šå‚³ Jira CSV"), type="csv")

df = None
default_loaded = None

if uploaded_file is None:
    for fn in ["Luanta_Final_Demo_Data_v1.csv", "Luanta_Final_Demo_Data.csv"]:
        try:
            df = pd.read_csv(fn)
            default_loaded = fn
            break
        except Exception:
            pass

    if df is not None:
        st.success(f"âœ… {tx('Loaded default sample data', 'å·²è¼‰å…¥é è¨­ç¯„ä¾‹è³‡æ–™')}ï¼š{default_loaded}")
        note(
            "You can upload a new CSV anytime from the sidebar.",
            "ä½ ä¹Ÿå¯ä»¥éš¨æ™‚åœ¨å·¦å´ä¸Šå‚³æ–°çš„ CSVã€‚",
        )
    else:
        st.warning("âš ï¸ " + tx("Please upload a Jira CSV to start.", "è«‹å…ˆåœ¨å·¦å´ä¸Šå‚³ Jira CSV æ‰èƒ½é–‹å§‹åˆ†æã€‚"))
else:
    df = pd.read_csv(uploaded_file)
    st.success(f"âœ… {tx('Successfully loaded uploaded file', 'å·²æˆåŠŸè®€å–ä¸Šå‚³æª”æ¡ˆ')}ï¼š{uploaded_file.name}")

if df is None:
    st.stop()

# =========================================================
# Debug / Preview
# =========================================================
with st.expander(tx("Debug info", "é™¤éŒ¯è³‡è¨Š"), expanded=False):
    st.write(tx("Detected columns", "åµæ¸¬åˆ°çš„æ¬„ä½") + ":", list(df.columns))
    st.write(tx("Row count", "è³‡æ–™ç­†æ•¸") + ":", len(df))

with st.expander(tx("Data preview (first 20 rows)", "è³‡æ–™é è¦½ï¼ˆå‰ 20 ç­†ï¼‰"), expanded=False):
    st.dataframe(df.head(20), use_container_width=True)

# =========================================================
# Column detection (robust)
# =========================================================
delay_col = safe_first_match(df.columns, ["delay_rate", "delay", "delay_rate_%"])
priority_col = "Priority" if "Priority" in df.columns else safe_first_match(df.columns, ["priority"])
role_col = "Role" if "Role" in df.columns else safe_first_match(df.columns, ["role", "team"])
status_col = "Status_Current" if "Status_Current" in df.columns else safe_first_match(df.columns, ["status_current", "status"])
last_updated_col = "Last_Updated_Date" if "Last_Updated_Date" in df.columns else safe_first_match(df.columns, ["last_updated", "updated"])
status_entered_col = "Status_Entered_Date" if "Status_Entered_Date" in df.columns else safe_first_match(df.columns, ["status_entered", "entered_date"])
issue_key_col = "Issue_Key" if "Issue_Key" in df.columns else safe_first_match(df.columns, ["issue_key", "key"])
summary_col = "Summary" if "Summary" in df.columns else safe_first_match(df.columns, ["summary", "title"])
assignee_col = "Assignee" if "Assignee" in df.columns else safe_first_match(df.columns, ["assignee", "owner"])
blocked_reason_col = "Blocked_Reason" if "Blocked_Reason" in df.columns else safe_first_match(df.columns, ["blocked_reason", "block_reason", "blocked"])
root_cause_col = "Root_Cause_Category" if "Root_Cause_Category" in df.columns else safe_first_match(df.columns, ["root_cause", "cause"])

# SLA columns
sla_breached_col = "SLA_Breached" if "SLA_Breached" in df.columns else safe_first_match(df.columns, ["sla_breached", "breach"])
resolution_days_col = "Resolution_Days" if "Resolution_Days" in df.columns else safe_first_match(df.columns, ["resolution_days", "resolution_time_days", "resolution"])
sla_target_col = "SLA_Target_Days" if "SLA_Target_Days" in df.columns else safe_first_match(df.columns, ["sla_target_days", "sla_days", "sla_target"])

# =========================================================
# SECTION: Key Metrics (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Key Metrics",
    "é—œéµæŒ‡æ¨™",
    "High-level KPIs for a quick health check.",
    "ç”¨å¹¾å€‹æ•¸å­—å¿«é€Ÿåˆ¤æ–·æ•´é«”å¥åº·åº¦ã€‚",
)

m1, m2, m3 = st.columns(3)
total_tickets = len(df)
m1.metric(tx("Total Tickets", "ç¸½å·¥å–®æ•¸"), total_tickets)

p0_count = "N/A"
if priority_col and priority_col in df.columns:
    p0_count = int(df[priority_col].astype(str).str.contains("P0", case=False, na=False).sum())
m2.metric(tx("P0 Critical Issues", "P0 é‡å¤§å·¥å–®æ•¸"), p0_count)

avg_delay = "N/A"
if delay_col and delay_col in df.columns:
    avg_delay_val = pd.to_numeric(df[delay_col], errors="coerce").mean()
    if pd.notna(avg_delay_val):
        avg_delay = f"{avg_delay_val:.1f}%"
m3.metric(tx("Avg. Delay Rate", "å¹³å‡å»¶é²ç‡"), avg_delay)

st.markdown("</div>", unsafe_allow_html=True)

# =========================================================
# SECTION: Performance Breakdown (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Performance Breakdown",
    "ç¸¾æ•ˆæ‹†è§£",
    "Break down delay by role/team to locate bottlenecks.",
    "ä¾è§’è‰²æ‹†è§£å»¶é²ï¼Œå®šä½ç“¶é ¸ã€‚",
)

if not role_col or not delay_col or role_col not in df.columns or delay_col not in df.columns:
    empty_state(
        "Not enough data to show delay breakdown by role. Need Role and Delay Rate columns.",
        "ç›®å‰è³‡æ–™ä¸è¶³ä»¥é¡¯ç¤ºè§’è‰²å»¶é²æ‹†è§£ï¼Œéœ€è¦ Role èˆ‡ Delay Rate æ¬„ä½ã€‚",
        tips=[
            "ç¢ºèª CSV æ˜¯å¦åŒ…å« Role",
            f"ç¢ºèªæ˜¯å¦åŒ…å«å»¶é²æ¬„ä½ï¼ˆä¾‹å¦‚ {delay_col or 'Delay_Rate_%'}ï¼‰",
        ],
    )
else:
    perf_df = df[[role_col, delay_col]].copy()
    perf_df[delay_col] = pd.to_numeric(perf_df[delay_col], errors="coerce")
    perf_df = perf_df.dropna(subset=[role_col, delay_col])
    perf_df = perf_df.groupby(role_col, as_index=False)[delay_col].mean().sort_values(delay_col, ascending=False)

    render_chart_or_empty(
        perf_df,
        chart_fn=lambda d: px.bar(
            d,
            x=role_col,
            y=delay_col,
            color=role_col,
            labels={delay_col: "Delay Rate (%)"},
            title=tx("Average Delay by Team Role", "å„è§’è‰²å¹³å‡å»¶é²"),
        ),
        empty_en="Not enough numeric values to compute average delay by role.",
        empty_zh="ç›®å‰è³‡æ–™ä¸è¶³ä»¥è¨ˆç®—è§’è‰²å¹³å‡å»¶é²ï¼Œå¸¸è¦‹åŸå› æ˜¯å»¶é²æ¬„ä½ç‚ºç©ºæˆ–ç„¡æ³•è½‰æˆæ•¸å­—ã€‚",
        tips=[
            "ç¢ºèª Delay æ¬„ä½æ˜¯å¦ç‚ºæ•¸å­—ï¼ˆä¾‹å¦‚ 12.3ï¼‰",
            "é¿å…æ··å…¥ % ç¬¦è™Ÿæˆ–æ–‡å­—ï¼ˆå¦‚ 12.3%ï¼‰",
        ],
    )

st.markdown("</div>", unsafe_allow_html=True)

# =========================================================
# SECTION: Workflow Finder (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Workflow Finder",
    "å·¥ä½œæµç¨‹åˆ†æ",
    "Use WIP and queue time to identify where the workflow is stuck.",
    "ç”¨åœ¨æ‰‹é‡èˆ‡ç­‰å¾…æ™‚é–“æ‰¾å‡ºæµç¨‹å¡é»ã€‚",
)

c1, c2 = st.columns(2)

# WIP by Status
with c1:
    st.markdown("<div class='soft-divider'></div>", unsafe_allow_html=True)
    st.markdown(f"### {tx('WIP by Status', 'å„ç‹€æ…‹åœ¨æ‰‹é‡')}")
    st.caption(tx("Current ticket distribution across statuses.", "å·¥å–®ç›®å‰åˆ†ä½ˆåœ¨å“ªäº›ç‹€æ…‹ã€‚"))

    if not status_col or status_col not in df.columns:
        empty_state(
            "Not enough data to compute WIP by status.",
            "ç›®å‰è³‡æ–™ä¸è¶³ä»¥è¨ˆç®—å„ç‹€æ…‹åœ¨æ‰‹é‡ï¼Œå¸¸è¦‹åŸå› æ˜¯ç¼ºå°‘ Status_Current æˆ–æ¬„ä½å…¨ç©ºã€‚",
            tips=[
                "ç¢ºèª CSV æ˜¯å¦åŒ…å« Status_Current",
                "ç¢ºèª Status_Current æ˜¯å¦æœ‰å€¼ï¼ˆä¸æ˜¯å…¨éƒ¨ç©ºç™½ï¼‰",
            ],
        )
    else:
        wip_df = (
            df[status_col]
            .dropna()
            .value_counts()
            .rename_axis("Status")
            .reset_index(name="Count")
        )

        # âœ… ç©ºå€¼æ™‚é¡¯ç¤ºä¸­æ€§æ–‡æ¡ˆï¼ˆä¸ç•™ç™½ï¼‰
        render_chart_or_empty(
            wip_df,
            chart_fn=lambda d: px.bar(d, x="Status", y="Count", title=tx("Current Work In Progress by Status", "å„ç‹€æ…‹åœ¨æ‰‹é‡")),
            empty_en="No usable status values found.",
            empty_zh="ç›®å‰æ²’æœ‰å¯ç”¨çš„ç‹€æ…‹è³‡æ–™å¯ä»¥é¡¯ç¤ºã€‚å¸¸è¦‹åŸå› æ˜¯ Status_Current éƒ½æ˜¯ç©ºå€¼æˆ–ç‹€æ…‹å‘½åä¸ä¸€è‡´ã€‚",
            tips=[
                "ç¢ºèª Status_Current æ˜¯å¦æœ‰ To Do / In Progress / Review / Done ç­‰å€¼",
                "å¦‚æœä½ çš„ç‹€æ…‹å‘½åä¸åŒï¼Œå»ºè­°å…ˆåœ¨ CSV çµ±ä¸€å‘½åæˆ–åœ¨ç¨‹å¼åŠ  mapping",
            ],
        )

# Queue Time by Status
with c2:
    st.markdown("<div class='soft-divider'></div>", unsafe_allow_html=True)
    st.markdown(f"### {tx('Queue Time (days) by Status', 'å„ç‹€æ…‹ç­‰å¾…æ™‚é–“ï¼ˆå¤©ï¼‰')}")
    st.caption(tx("Average time tickets stay in each status.", "å·¥å–®åœ¨æ¯å€‹ç‹€æ…‹å¹³å‡åœç•™å¤šä¹…ï¼Œç”¨ä¾†æ‰¾æœ€æ…¢ç¯€é»ã€‚"))

    q_df = pd.DataFrame()
    if status_col and status_entered_col and status_col in df.columns and status_entered_col in df.columns:
        tmp = df[[status_col, status_entered_col]].copy()
        tmp[status_entered_col] = to_datetime_safe(tmp[status_entered_col])
        now_utc = pd.Timestamp.now(tz=timezone.utc)
        tmp["_queue_days"] = (now_utc - tmp[status_entered_col]).dt.total_seconds() / 86400.0
        tmp = tmp.dropna(subset=[status_col, "_queue_days"])
        q_df = tmp.groupby(status_col, as_index=False)["_queue_days"].mean().sort_values("_queue_days", ascending=False)

    # âœ… ç©ºå€¼æ™‚é¡¯ç¤ºä¸­æ€§æ–‡æ¡ˆï¼ˆä¸ç•™ç™½ï¼‰
    render_chart_or_empty(
        q_df,
        chart_fn=lambda d: px.bar(d, x=status_col, y="_queue_days", title=tx("Average Queue Time by Status (days)", "å„ç‹€æ…‹å¹³å‡ç­‰å¾…æ™‚é–“ï¼ˆå¤©ï¼‰")),
        empty_en="Not enough data to compute queue time by status.",
        empty_zh="ç›®å‰ç„¡æ³•è¨ˆç®—ç­‰å¾…æ™‚é–“ã€‚å¸¸è¦‹åŸå› æ˜¯ç¼ºå°‘ Status_Entered_Dateï¼Œæˆ–æ—¥æœŸæ ¼å¼ç„¡æ³•è§£æã€‚",
        tips=[
            "ç¢ºèª CSV æ˜¯å¦åŒ…å« Status_Entered_Date",
            "æ—¥æœŸå»ºè­°ä½¿ç”¨ ISO æ ¼å¼ï¼Œä¾‹å¦‚ 2025-01-01 18:34:25+00:00",
        ],
    )

st.markdown("</div>", unsafe_allow_html=True)

# =========================================================
# SECTION: Stale Tickets (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Stale Tickets",
    "ä¹…æœªæ›´æ–°å·¥å–®",
    "Tickets not updated for a long time; often indicates work is stuck.",
    "é•·æ™‚é–“æœªæ›´æ–°ï¼Œå¸¸ä»£è¡¨æµç¨‹å¡ä½æˆ–ç¼ºä¹æ¨é€²ã€‚",
)

stale_df = pd.DataFrame()

if last_updated_col and last_updated_col in df.columns:
    tmp = df.copy()
    tmp[last_updated_col] = to_datetime_safe(tmp[last_updated_col])
    now_utc = pd.Timestamp.now(tz=timezone.utc)
    tmp["_stale_days"] = (now_utc - tmp[last_updated_col]).dt.total_seconds() / 86400.0

    threshold = st.slider(tx("Stale threshold (days)", "ä¹…æœªæ›´æ–°é–€æª»ï¼ˆå¤©ï¼‰"), 1, 180, 30)

    stale_df = tmp.dropna(subset=["_stale_days"])
    stale_df = stale_df[stale_df["_stale_days"] >= threshold].sort_values("_stale_days", ascending=False)

    show_cols = []
    for c in [issue_key_col, summary_col, priority_col, role_col, status_col, last_updated_col, "_stale_days"]:
        if c and c in stale_df.columns:
            show_cols.append(c)

    if stale_df.empty:
        empty_state(
            "No tickets exceed the stale threshold, or timestamps are missing.",
            "ç›®å‰æ²’æœ‰ç¬¦åˆé–€æª»çš„ä¹…æœªæ›´æ–°å·¥å–®ï¼Œæˆ–æ›´æ–°æ™‚é–“è³‡æ–™ä¸è¶³ä»¥è¨ˆç®—ã€‚",
            tips=[
                "å¦‚æœä½ é æœŸæœƒæœ‰è³‡æ–™ï¼Œè«‹ç¢ºèª Last_Updated_Date æ˜¯å¦å­˜åœ¨ä¸”ç‚ºå¯è§£ææ—¥æœŸ",
                "å¯å…ˆæŠŠé–€æª»å¤©æ•¸èª¿å°çœ‹çœ‹",
            ],
        )
    else:
        st.dataframe(stale_df[show_cols], use_container_width=True)
else:
    empty_state(
        "Not enough data to compute stale tickets. Missing Last_Updated_Date or invalid datetime format.",
        "ç›®å‰ç„¡æ³•è¨ˆç®—ä¹…æœªæ›´æ–°å·¥å–®ã€‚å¸¸è¦‹åŸå› æ˜¯ç¼ºå°‘ Last_Updated_Date æˆ–æ—¥æœŸæ ¼å¼ç„¡æ³•è§£æã€‚",
        tips=[
            "ç¢ºèª CSV æ˜¯å¦åŒ…å« Last_Updated_Date",
            "æ—¥æœŸå»ºè­°ç”¨ ISO æ ¼å¼ï¼Œä¾‹å¦‚ 2025-01-01 18:34:25+00:00",
        ],
    )

st.markdown("</div>", unsafe_allow_html=True)

# =========================================================
# SECTION: SLA / Risk (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "SLA / Risk",
    "SLA èˆ‡é¢¨éšª",
    "Estimate SLA breach risk if SLA columns exist.",
    "è‹¥æœ‰ SLA æ¬„ä½ï¼Œä¼°ç®—é•ç´„é¢¨éšªã€‚",
)

sla_df = pd.DataFrame()
sla_breach_rate = None
tmp = df.copy()

if sla_breached_col and sla_breached_col in tmp.columns:
    tmp[sla_breached_col] = tmp[sla_breached_col].astype(str).str.lower().isin(["true", "1", "yes", "y"])
    if priority_col and priority_col in tmp.columns:
        sla_df = tmp.groupby(priority_col, as_index=False)[sla_breached_col].mean()
        sla_df["Breach Rate (%)"] = (sla_df[sla_breached_col] * 100).round(2)
        sla_breach_rate = float(tmp[sla_breached_col].mean() * 100)

elif resolution_days_col and sla_target_col and resolution_days_col in tmp.columns and sla_target_col in tmp.columns:
    tmp[resolution_days_col] = pd.to_numeric(tmp[resolution_days_col], errors="coerce")
    tmp[sla_target_col] = pd.to_numeric(tmp[sla_target_col], errors="coerce")
    tmp["_sla_breached"] = (tmp[resolution_days_col] > tmp[sla_target_col])
    if priority_col and priority_col in tmp.columns:
        sla_df = tmp.groupby(priority_col, as_index=False)["_sla_breached"].mean()
        sla_df["Breach Rate (%)"] = (sla_df["_sla_breached"] * 100).round(2)
        sla_breach_rate = float(tmp["_sla_breached"].mean() * 100)

if sla_breach_rate is None:
    empty_state(
        "SLA fields not available. Cannot compute breach rate.",
        "ç¼ºå°‘ SLA æ¬„ä½ï¼Œç„¡æ³•è¨ˆç®—é•ç´„ç‡ã€‚",
        tips=[
            "æä¾› SLA_Breachedï¼ˆtrue/falseï¼‰æœ€ç°¡å–®",
            "æˆ–æä¾› Resolution_Days + SLA_Target_Days ä¹Ÿå¯æ¨ç®—",
        ],
    )
else:
    st.write(f"**{tx('SLA Breach Rate', 'SLA é•ç´„ç‡')}**: {sla_breach_rate:.1f}%")
    if not sla_df.empty:
        show_cols = [priority_col, "Breach Rate (%)"] if (priority_col and priority_col in sla_df.columns) else ["Breach Rate (%)"]
        st.dataframe(sla_df[show_cols], use_container_width=True)

st.markdown("</div>", unsafe_allow_html=True)

# =========================================================
# SECTION: Root Cause Breakdown (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Root Cause Breakdown",
    "æ ¹å› åˆ†ä½ˆ",
    "Aggregate root causes to inform process improvements.",
    "å½™æ•´æ ¹å› ï¼ŒæŒ‡å‘æµç¨‹æ”¹å–„ã€‚",
)

if not root_cause_col or root_cause_col not in df.columns:
    empty_state(
        "Missing Root_Cause_Category. Cannot show distribution.",
        "ç¼ºå°‘ Root_Cause_Categoryï¼Œç„¡æ³•é¡¯ç¤ºæ ¹å› åˆ†ä½ˆã€‚",
        tips=["å»ºè­°åŠ å…¥ Root_Cause_Categoryï¼Œä¾‹å¦‚ Spec/Requirementã€API Dependencyã€Data/DB ç­‰"],
    )
else:
    rc = df[root_cause_col].dropna()
    if rc.empty:
        empty_state(
            "Root cause column exists but contains no usable values.",
            "æ ¹å› æ¬„ä½å­˜åœ¨ï¼Œä½†ç›®å‰æ²’æœ‰å¯ç”¨å€¼ï¼ˆå¯èƒ½å…¨ç©ºï¼‰ã€‚",
            tips=["ç¢ºèª Root_Cause_Category æ˜¯å¦æœ‰å¡«å€¼"],
        )
    else:
        rc_df = rc.value_counts().reset_index()
        rc_df.columns = ["Root Cause", "Count"]

        render_chart_or_empty(
            rc_df,
            chart_fn=lambda d: px.pie(d, names="Root Cause", values="Count", title=tx("Root Cause Distribution", "æ ¹å› åˆ†ä½ˆ")),
            empty_en="Unable to render root cause distribution.",
            empty_zh="ç›®å‰ç„¡æ³•é¡¯ç¤ºæ ¹å› åˆ†ä½ˆï¼ˆè³‡æ–™å¯èƒ½ä¸è¶³ï¼‰ã€‚",
        )

st.markdown("</div>", unsafe_allow_html=True)

# =========================================================
# SECTION: Blocked Details (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Blocked Details",
    "å¡é—œæ˜ç´°",
    "Blocked tickets and reasons; good for action items.",
    "åˆ—å‡ºå¡é—œå·¥å–®èˆ‡åŸå› ï¼Œæ–¹ä¾¿æ¨é€²ã€‚",
)

blocked_df = pd.DataFrame()
if status_col and status_col in df.columns:
    blocked_df = df[df[status_col].astype(str).str.lower().eq("blocked")].copy()

if blocked_df.empty and blocked_reason_col and blocked_reason_col in df.columns:
    blocked_df = df[df[blocked_reason_col].notna()].copy()

if blocked_df.empty:
    empty_state(
        "No blocked tickets detected.",
        "ç›®å‰æ²’æœ‰è¾¨è­˜åˆ°å¡é—œå·¥å–®ã€‚",
        tips=[
            "ç¢ºèª Status_Current æ˜¯å¦æœ‰ Blocked",
            "æˆ–æä¾› Blocked_Reason æ¬„ä½ä»¥åˆ©è¾¨è­˜",
        ],
    )
else:
    st.write(f"**{tx('Blocked tickets', 'å¡é—œå·¥å–®æ•¸')}**: {len(blocked_df)}")
    cols = []
    for c in [issue_key_col, summary_col, priority_col, role_col, assignee_col, blocked_reason_col, status_col]:
        if c and c in blocked_df.columns:
            cols.append(c)
    st.dataframe(blocked_df[cols].head(50), use_container_width=True)

st.markdown("</div>", unsafe_allow_html=True)

# =========================================================
# SECTION: Executive Summary (Card)
# =========================================================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Executive Summary",
    "ä¸»ç®¡æ‘˜è¦",
    "Neutral, action-oriented talking points.",
    "ä¸­æ€§ä¸”å¯è¡Œå‹•çš„ä¸»ç®¡é‡é»ã€‚",
)

if st.button(tx("Generate Executive Report", "ç”¢å‡ºä¸»ç®¡æ‘˜è¦")):
    bullets = []

    # Delay bottleneck
    if role_col and delay_col and role_col in df.columns and delay_col in df.columns:
        tmp2 = df[[role_col, delay_col]].copy()
        tmp2[delay_col] = pd.to_numeric(tmp2[delay_col], errors="coerce")
        tmp2 = tmp2.dropna(subset=[role_col, delay_col])
        if not tmp2.empty:
            r = tmp2.groupby(role_col)[delay_col].mean().sort_values(ascending=False)
            top_role = r.index[0]
            bullets.append(tx(
                f"- Delay bottleneck: {top_role} has the highest average delay ({r.iloc[0]:.1f}%).",
                f"- å»¶é²ç“¶é ¸ï¼š{top_role} å¹³å‡å»¶é²æœ€é«˜ï¼ˆ{r.iloc[0]:.1f}%ï¼‰ã€‚"
            ))
        else:
            bullets.append(tx(
                "- Delay bottleneck: insufficient numeric delay data.",
                "- å»¶é²ç“¶é ¸ï¼šå»¶é²æ¬„ä½ç¼ºä¹å¯ç”¨æ•¸å­—è³‡æ–™ã€‚"
            ))
    else:
        bullets.append(tx(
            "- Delay bottleneck: missing Role/Delay columns.",
            "- å»¶é²ç“¶é ¸ï¼šç¼ºå°‘ Role æˆ– Delay æ¬„ä½ã€‚"
        ))

    # Queue bottleneck
    if status_col and status_entered_col and status_col in df.columns and status_entered_col in df.columns:
        tmp3 = df[[status_col, status_entered_col]].copy()
        tmp3[status_entered_col] = to_datetime_safe(tmp3[status_entered_col])
        now_utc = pd.Timestamp.now(tz=timezone.utc)
        tmp3["_queue_days"] = (now_utc - tmp3[status_entered_col]).dt.total_seconds() / 86400.0
        tmp3 = tmp3.dropna(subset=[status_col, "_queue_days"])
        if not tmp3.empty:
            q = tmp3.groupby(status_col)["_queue_days"].mean().sort_values(ascending=False)
            top_status = q.index[0]
            bullets.append(tx(
                f"- Queue bottleneck: {top_status} has the longest average queue time ({q.iloc[0]:.1f} days).",
                f"- ç­‰å¾…ç“¶é ¸ï¼š{top_status} å¹³å‡ç­‰å¾…æ™‚é–“æœ€é•·ï¼ˆ{q.iloc[0]:.1f} å¤©ï¼‰ã€‚"
            ))
        else:
            bullets.append(tx(
                "- Queue bottleneck: no usable queue-time values.",
                "- ç­‰å¾…ç“¶é ¸ï¼šç¼ºä¹å¯ç”¨ç­‰å¾…æ™‚é–“è³‡æ–™ã€‚"
            ))
    else:
        bullets.append(tx(
            "- Queue bottleneck: missing Status_Entered_Date; cannot compute queue time.",
            "- ç­‰å¾…ç“¶é ¸ï¼šç¼ºå°‘ Status_Entered_Dateï¼Œç„¡æ³•è¨ˆç®—ç­‰å¾…æ™‚é–“ã€‚"
        ))

    # SLA risk
    if sla_breach_rate is not None:
        bullets.append(tx(
            f"- SLA risk: breach rate is {sla_breach_rate:.1f}%.",
            f"- SLA é¢¨éšªï¼šé•ç´„ç‡ {sla_breach_rate:.1f}%ã€‚"
        ))
    else:
        bullets.append(tx(
            "- SLA risk: SLA fields not available; not computed.",
            "- SLA é¢¨éšªï¼šç¼ºå°‘ SLA æ¬„ä½ï¼Œæœªè¨ˆç®—ã€‚"
        ))

    # Root cause
    if root_cause_col and root_cause_col in df.columns:
        rc = df[root_cause_col].dropna()
        if not rc.empty:
            top_cause = rc.value_counts().index[0]
            bullets.append(tx(
                f"- Primary root cause: {top_cause} is the most frequent category.",
                f"- ä¸»è¦æ ¹å› ï¼š{top_cause} æ˜¯æœ€å¸¸è¦‹åˆ†é¡ã€‚"
            ))
        else:
            bullets.append(tx(
                "- Primary root cause: values are empty.",
                "- ä¸»è¦æ ¹å› ï¼šæ ¹å› æ¬„ä½ç›®å‰æ²’æœ‰æœ‰æ•ˆå€¼ã€‚"
            ))
    else:
        bullets.append(tx(
            "- Primary root cause: missing Root_Cause_Category.",
            "- ä¸»è¦æ ¹å› ï¼šç¼ºå°‘ Root_Cause_Categoryã€‚"
        ))

    st.markdown("\n".join(bullets))

st.markdown("</div>", unsafe_allow_html=True)


import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import timezone

# =========================
# Page config
# =========================
st.set_page_config(page_title="Luanta Service Dashboard", layout="wide")

# =========================
# Global CSS (Dashboard cards + unified typography)
# =========================
st.markdown(
    """
<style>
.block-container { padding-top: 1.1rem; padding-bottom: 2rem; max-width: 1200px; }
section[data-testid="stSidebar"] .block-container { padding-top: 1rem; }

/* Section card */
.section-card {
  border: 1px solid rgba(49, 51, 63, 0.14);
  background: #ffffff;
  border-radius: 16px;
  padding: 18px 18px 14px 18px;
  margin: 16px 0 18px 0;
  box-shadow: 0 6px 20px rgba(0,0,0,0.06);
}

/* Remove any visual dividers */
.soft-divider { display: none !important; }

/* Typography hierarchy */
.section-title { font-size: 1.40rem; font-weight: 780; margin: 0 0 0.15rem 0; }
.section-subtitle { font-size: 0.95rem; opacity: 0.72; margin: 0 0 0.85rem 0; }

.kpi-title { font-size: 1.10rem; font-weight: 760; margin: 0.2rem 0 0.2rem 0; }
.kpi-sub { font-size: 0.90rem; opacity: 0.72; margin: 0 0 0.55rem 0; }

.chart-title { font-size: 1.08rem; font-weight: 760; margin: 0.70rem 0 0.10rem 0; }
.chart-desc { font-size: 0.90rem; opacity: 0.72; margin: 0 0 0.60rem 0; }

.note {
  border-left: 4px solid rgba(0, 123, 255, 0.55);
  padding: 10px 12px;
  background: rgba(0, 123, 255, 0.06);
  border-radius: 12px;
  margin: 8px 0 10px 0;
}

.empty {
  border-left: 4px solid rgba(255, 193, 7, 0.75);
  padding: 10px 12px;
  background: rgba(255, 193, 7, 0.12);
  border-radius: 12px;
  margin: 8px 0 10px 0;
}

.small-muted { font-size: 0.85rem; opacity: 0.70; }

/* Make Streamlit metric look more dashboard-like */
[data-testid="stMetric"] {
  border: 1px solid rgba(49, 51, 63, 0.12);
  border-radius: 14px;
  padding: 10px 12px;
  background: #fff;
}
</style>
""",
    unsafe_allow_html=True,
)

# =========================
# Language utilities
# =========================
def tx(en: str, zh: str) -> str:
    return zh if st.session_state.get("lang", "zh") == "zh" else en

def card_title(en_title: str, zh_title: str, en_sub: str = "", zh_sub: str = ""):
    st.markdown(
        f"<div class='section-title'>{tx(en_title, zh_title)}</div>",
        unsafe_allow_html=True,
    )
    if (en_sub or zh_sub):
        st.markdown(
            f"<div class='section-subtitle'>{tx(en_sub, zh_sub)}</div>",
            unsafe_allow_html=True,
        )

def note(en_text: str, zh_text: str):
    st.markdown(
        f"<div class='note'>{tx(en_text, zh_text)}</div>",
        unsafe_allow_html=True,
    )

def empty_state(en_text: str, zh_text: str, tips=None):
    st.markdown(
        f"<div class='empty'>{tx(en_text, zh_text)}</div>",
        unsafe_allow_html=True,
    )
    if tips:
        st.markdown("<div class='small-muted'>", unsafe_allow_html=True)
        for t in tips:
            st.write("â€¢ " + t)
        st.markdown("</div>", unsafe_allow_html=True)

def to_datetime_safe(s: pd.Series) -> pd.Series:
    return pd.to_datetime(s, errors="coerce", utc=True)

def render_chart_or_empty(df_plot: pd.DataFrame, chart_fn, empty_en: str, empty_zh: str, tips=None):
    if df_plot is None or df_plot.empty:
        empty_state(empty_en, empty_zh, tips=tips)
        return
    fig = chart_fn(df_plot)
    st.plotly_chart(fig, use_container_width=True)

# =========================
# Sidebar - upload + language toggle
# =========================
st.sidebar.header("è¨­å®š / Settings")
lang = st.sidebar.radio(
    "ä»‹é¢èªè¨€ / Language",
    options=["ä¸­æ–‡", "English"],
    index=0,
)
st.session_state["lang"] = "zh" if lang == "ä¸­æ–‡" else "en"

st.sidebar.header(tx("Step 1 Upload Data", "æ­¥é©Ÿä¸€ ä¸Šå‚³è³‡æ–™"))
uploaded_file = st.sidebar.file_uploader(tx("Upload Jira CSV", "ä¸Šå‚³ Jira CSV"), type="csv")

# =========================
# Load data
# =========================
df = None
loaded_from = None

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        loaded_from = uploaded_file.name
        st.success(tx(f"Loaded uploaded file: {loaded_from}", f"å·²æˆåŠŸè®€å–ä¸Šå‚³æª”æ¡ˆï¼š{loaded_from}"))
    except Exception as e:
        df = None
        st.error(tx("Failed to read the uploaded CSV.", "ç„¡æ³•è®€å–ä½ ä¸Šå‚³çš„ CSVã€‚"))
        st.exception(e)
else:
    # Default: try v1 first, then fallback
    for fname in ["Luanta_Final_Demo_Data_v1.csv", "Luanta_Final_Demo_Data.csv"]:
        try:
            df = pd.read_csv(fname)
            loaded_from = fname
            st.info(tx(f"Using default demo data: {fname}", f"ç›®å‰ä½¿ç”¨é è¨­ç¯„ä¾‹è³‡æ–™ï¼š{fname}"))
            break
        except Exception:
            df = None

if df is None:
    st.warning(tx("Please upload a Jira CSV in the sidebar to start.", "è«‹åœ¨å·¦å´ä¸Šå‚³ Jira CSV æ‰èƒ½é–‹å§‹åˆ†æã€‚"))
    st.stop()

# =========================
# Column detection (robust)
# =========================
def find_col(candidates):
    cols_lower = {c.lower(): c for c in df.columns}
    for cand in candidates:
        if cand.lower() in cols_lower:
            return cols_lower[cand.lower()]
    # fuzzy: contains
    for c in df.columns:
        for cand in candidates:
            if cand.lower() in c.lower():
                return c
    return None

created_col = find_col(["Created_Date", "Created Date"])
issue_key_col = find_col(["Issue_Key", "Issue Key", "Key"])
summary_col = find_col(["Summary", "Task", "Title"])
role_col = find_col(["Role", "Team", "Assignee_Role"])
priority_col = find_col(["Priority"])
estimate_col = find_col(["Estimate_Hrs", "Estimate Hours", "Original Estimate"])
actual_col = find_col(["Actual_Hrs", "Actual Hours", "Time Spent"])
reopen_col = find_col(["Re_open_Count", "Reopen Count", "Reopen"])
delay_col = find_col(["Delay_Rate_%", "Delay Rate", "Delay"])
status_col = find_col(["Status_Current", "Status", "Current Status"])
status_entered_col = find_col(["Status_Entered_Date", "Status Entered", "Entered Date"])
last_updated_col = find_col(["Last_Updated_Date", "Updated", "Updated Date"])
assignee_col = find_col(["Assignee", "Owner"])
blocked_reason_col = find_col(["Blocked_Reason", "Block Reason", "Blocked Reason"])
root_cause_col = find_col(["Root_Cause", "Root Cause", "Category"])

# =========================
# Header
# =========================
st.markdown(
    f"<div class='section-card'>"
    f"<div class='section-title'>ğŸ {tx('Luanta Service Performance Dashboard', 'Luanta æœå‹™æ•ˆèƒ½å„€è¡¨æ¿')}</div>"
    f"<div class='section-subtitle'>{tx('Upload a Jira export CSV to find bottlenecks and risks.', 'ä¸Šå‚³ Jira åŒ¯å‡º CSVï¼Œå”åŠ©æ‰¾å‡ºæµç¨‹å¡é»èˆ‡é¢¨éšªã€‚')}</div>"
    f"<div class='small-muted'>{tx('Data source', 'è³‡æ–™ä¾†æº')}ï¼š{loaded_from}</div>"
    f"</div>",
    unsafe_allow_html=True,
)

# =========================
# Data preview (to address: "csv has many columns but only show some")
# =========================
with st.expander(tx("Debug info and data preview", "é™¤éŒ¯è³‡è¨Šèˆ‡è³‡æ–™é è¦½")):
    st.write(tx("Detected columns used in analysis:", "ç³»çµ±åµæ¸¬åˆ°ä¸¦ç”¨æ–¼åˆ†æçš„æ¬„ä½ï¼š"))
    detected = {
        "created_col": created_col,
        "issue_key_col": issue_key_col,
        "summary_col": summary_col,
        "role_col": role_col,
        "priority_col": priority_col,
        "estimate_col": estimate_col,
        "actual_col": actual_col,
        "reopen_col": reopen_col,
        "delay_col": delay_col,
        "status_col": status_col,
        "status_entered_col": status_entered_col,
        "last_updated_col": last_updated_col,
        "assignee_col": assignee_col,
        "blocked_reason_col": blocked_reason_col,
        "root_cause_col": root_cause_col,
    }
    st.json(detected)
    st.write(tx("First 20 rows:", "å‰ 20 ç­†è³‡æ–™ï¼š"))
    st.dataframe(df.head(20), use_container_width=True)
    st.write(tx("All columns in the CSV:", "CSV å…¨éƒ¨æ¬„ä½ï¼š"))
    st.write(list(df.columns))

# =========================
# SECTION: Key Metrics
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Key Metrics",
    "é—œéµæŒ‡æ¨™",
    "High-level snapshot of ticket volume and delay.",
    "å¿«é€ŸæŒæ¡å·¥å–®é‡èˆ‡å»¶èª¤ç‹€æ³ã€‚",
)

total_tickets = len(df)

# P0 definition (robust)
p0_count = "N/A"
if priority_col and priority_col in df.columns:
    p0_count = int(df[priority_col].astype(str).str.contains("P0", case=False, na=False).sum())

avg_delay = "N/A"
if delay_col and delay_col in df.columns:
    try:
        avg_delay_val = pd.to_numeric(df[delay_col], errors="coerce").mean()
        if pd.notna(avg_delay_val):
            avg_delay = f"{avg_delay_val:.1f}%"
    except Exception:
        pass

m1, m2, m3 = st.columns(3)
m1.metric(tx("Total Tickets", "å·¥å–®ç¸½æ•¸"), total_tickets)
m2.metric(tx("P0 Critical Issues", "P0 é«˜é¢¨éšªå·¥å–®"), p0_count)
m3.metric(tx("Average Delay Rate", "å¹³å‡å»¶èª¤ç‡"), avg_delay)

note(
    "Why some columns are not shown: each section only displays fields relevant to its analysis.",
    "ç‚ºä½•åªé¡¯ç¤ºéƒ¨åˆ†æ¬„ä½ï¼šæ¯å€‹å€å¡Šåªæœƒå‘ˆç¾è©²åˆ†æéœ€è¦çš„æ¬„ä½ï¼Œé¿å…æŠŠæ•´ä»½ CSV å…¨éƒ¨å¡ä¸Šä¾†é€ æˆé–±è®€è² æ“”ã€‚",
)

st.markdown("</div>", unsafe_allow_html=True)

# =========================
# SECTION: Performance Breakdown
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Performance Breakdown",
    "æ•ˆèƒ½æ‹†è§£",
    "Compare delay across roles and identify hotspots.",
    "æ¯”è¼ƒä¸åŒè§’è‰²çš„å»¶èª¤ç¨‹åº¦ï¼Œå®šä½ç†±å€ã€‚",
)

if not (role_col and delay_col and role_col in df.columns and delay_col in df.columns):
    empty_state(
        "Not enough data to compute delay by role.",
        "è³‡æ–™ä¸è¶³ä»¥è¨ˆç®—å„è§’è‰²çš„å»¶èª¤ã€‚",
        tips=[
            tx("Missing Role or Delay column.", "ç¼ºå°‘ Role æˆ– Delay æ¬„ä½ã€‚"),
            tx("Check your CSV export mapping.", "è«‹ç¢ºèªåŒ¯å‡º CSV çš„æ¬„ä½æ˜¯å¦ç¬¦åˆã€‚"),
        ],
    )
else:
    tmp = df[[role_col, delay_col]].copy()
    tmp[delay_col] = pd.to_numeric(tmp[delay_col], errors="coerce")
    role_delay = tmp.dropna().groupby(role_col, as_index=False)[delay_col].mean().sort_values(delay_col, ascending=False)

    st.markdown(f"<div class='chart-title'>{tx('Average Delay by Role', 'å„è§’è‰²å¹³å‡å»¶èª¤')}</div>", unsafe_allow_html=True)
    st.markdown(f"<div class='chart-desc'>{tx('Higher means more overrun relative to estimate.', 'æ•¸å€¼è¶Šé«˜ä»£è¡¨è¶Šå®¹æ˜“è¶…å‡ºé ä¼°å·¥æ™‚ã€‚')}</div>", unsafe_allow_html=True)

    render_chart_or_empty(
        role_delay,
        chart_fn=lambda d: px.bar(
            d, x=role_col, y=delay_col, color=role_col,
            title=tx("Average Delay by Team Role", "å„è§’è‰²å¹³å‡å»¶èª¤ç‡"),
            labels={delay_col: tx("Delay Rate", "å»¶èª¤ç‡")}
        ),
        empty_en="No usable delay data found.",
        empty_zh="ç›®å‰æ²’æœ‰å¯ç”¨çš„å»¶èª¤è³‡æ–™å¯ä»¥é¡¯ç¤ºã€‚",
        tips=[
            tx("Delay column must be numeric.", "Delay æ¬„ä½éœ€è¦æ˜¯æ•¸å­—ã€‚"),
            tx("If values contain symbols, remove them in export.", "å¦‚æœå«æœ‰ç¬¦è™Ÿï¼Œè«‹åœ¨åŒ¯å‡ºæ™‚ç§»é™¤æˆ–åœ¨ç¨‹å¼è½‰æ›ã€‚"),
        ],
    )

st.markdown("</div>", unsafe_allow_html=True)

# =========================
# SECTION: Workflow Finder
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Workflow Finder",
    "å·¥ä½œæµç¨‹åˆ†æ",
    "Use WIP and queue time to locate where work gets stuck.",
    "ç”¨åœ¨æ‰‹é‡èˆ‡ç­‰å¾…æ™‚é–“æ‰¾å‡ºæµç¨‹å¡é»ã€‚",
)

note(
    "How to read: WIP shows volume. Queue time shows waiting. Long queue time often means dependency, unclear next action, or overloaded intake.",
    "å¦‚ä½•è§£è®€ï¼šåœ¨æ‰‹é‡ä»£è¡¨å †ç©çš„æ•¸é‡ã€‚ç­‰å¾…æ™‚é–“ä»£è¡¨å¡å¤šä¹…ã€‚ç­‰å¾…æ™‚é–“é•·é€šå¸¸æ„å‘³å¤–éƒ¨ä¾è³´ã€ç¼ºå°‘æ˜ç¢ºä¸‹ä¸€æ­¥ã€æˆ–å‰æ®µæ’ç¨‹å¡ä½ã€‚",
)

c1, c2 = st.columns(2)

# WIP by Status
with c1:
    st.markdown(f"<div class='chart-title'>{tx('WIP by Status','å„ç‹€æ…‹åœ¨æ‰‹é‡')}</div>", unsafe_allow_html=True)
    st.markdown(f"<div class='chart-desc'>{tx('Ticket count in each status.', 'å„ç‹€æ…‹ç›®å‰æœ‰å¤šå°‘å·¥å–®ã€‚')}</div>", unsafe_allow_html=True)

    if not (status_col and status_col in df.columns):
        empty_state(
            "Not enough data to show WIP by status.",
            "è³‡æ–™ä¸è¶³ä»¥é¡¯ç¤ºå„ç‹€æ…‹åœ¨æ‰‹é‡ã€‚",
            tips=[
                tx("Missing Status_Current column.", "ç¼ºå°‘ Status_Current æ¬„ä½ã€‚"),
            ],
        )
    else:
        wip_df = df[status_col].dropna().astype(str).value_counts().rename_axis("Status").reset_index(name="Count")
        render_chart_or_empty(
            wip_df,
            chart_fn=lambda d: px.bar(
                d, x="Status", y="Count",
                title=tx("Current Work In Progress by Status", "å„ç‹€æ…‹åœ¨æ‰‹é‡")
            ),
            empty_en="No usable status values found.",
            empty_zh="ç›®å‰æ²’æœ‰å¯ç”¨çš„ç‹€æ…‹è³‡æ–™å¯ä»¥é¡¯ç¤ºã€‚",
            tips=[
                tx("Check if status values exist in the CSV.", "è«‹ç¢ºèªç‹€æ…‹æ¬„ä½åœ¨ CSV å…§æœ‰å€¼ã€‚"),
            ],
        )

# Queue time by Status
with c2:
    st.markdown(f"<div class='chart-title'>{tx('Queue Time by Status','å„ç‹€æ…‹ç­‰å¾…æ™‚é–“')}</div>", unsafe_allow_html=True)
    st.markdown(f"<div class='chart-desc'>{tx('Average days tickets have stayed in each status.', 'å·¥å–®åœ¨æ¯å€‹ç‹€æ…‹å¹³å‡åœç•™å¹¾å¤©ã€‚')}</div>", unsafe_allow_html=True)

    q_df = pd.DataFrame()
    if status_col and status_entered_col and status_col in df.columns and status_entered_col in df.columns:
        tmp = df[[status_col, status_entered_col]].copy()
        tmp[status_entered_col] = to_datetime_safe(tmp[status_entered_col])
        now_utc = pd.Timestamp.now(tz=timezone.utc)
        tmp["_queue_days"] = (now_utc - tmp[status_entered_col]).dt.total_seconds() / 86400.0
        tmp = tmp.dropna(subset=[status_col, "_queue_days"])
        q_df = tmp.groupby(status_col, as_index=False)["_queue_days"].mean().sort_values("_queue_days", ascending=False)

    render_chart_or_empty(
        q_df,
        chart_fn=lambda d: px.bar(
            d, x=status_col, y="_queue_days",
            title=tx("Average Queue Time by Status", "å„ç‹€æ…‹å¹³å‡ç­‰å¾…æ™‚é–“")
        ),
        empty_en="Not enough data to compute queue time. Missing entered date or invalid datetime format.",
        empty_zh="ç„¡æ³•è¨ˆç®—ç­‰å¾…æ™‚é–“ï¼Œå¯èƒ½ç¼ºå°‘é€²å…¥ç‹€æ…‹çš„æ™‚é–“æˆ–æ—¥æœŸæ ¼å¼ç„¡æ³•è§£æã€‚",
        tips=[
            tx("Required: Status_Entered_Date in ISO datetime.", "éœ€è¦ Status_Entered_Date ä¸”å»ºè­° ISO æ—¥æœŸæ ¼å¼ã€‚"),
            tx("Example: 2025-01-01 18:34:25+00:00", "ä¾‹å¦‚ï¼š2025-01-01 18:34:25+00:00"),
        ],
    )

if not q_df.empty:
    top_status = str(q_df.iloc[0][status_col])
    top_days = float(q_df.iloc[0]["_queue_days"])
    note(
        f"Interpretation hint: {top_status} has the longest average waiting time {top_days:.0f} days. This is a good candidate for workflow improvement.",
        f"è§£è®€æç¤ºï¼š{top_status} å¹³å‡ç­‰å¾…æ™‚é–“æœ€é«˜ {top_days:.0f} å¤©ï¼Œé€šå¸¸æ˜¯æµç¨‹å„ªåŒ–çš„å„ªå…ˆç›®æ¨™ã€‚",
    )

st.markdown("</div>", unsafe_allow_html=True)

# =========================
# SECTION: SLA / Risk
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "SLA and Risk",
    "SLA èˆ‡é¢¨éšª",
    "Estimate potential SLA breach based on delay and priority.",
    "ç”¨å»¶èª¤èˆ‡å„ªå…ˆç´šæ¨ä¼°å¯èƒ½çš„ SLA é¢¨éšªã€‚",
)

sla_breach_rate = None
sla_table = pd.DataFrame()

if priority_col and delay_col and priority_col in df.columns and delay_col in df.columns:
    tmp = df[[priority_col, delay_col]].copy()
    tmp[delay_col] = pd.to_numeric(tmp[delay_col], errors="coerce")
    tmp = tmp.dropna(subset=[priority_col, delay_col])

    # simple rule: delay >= 100 considered "breach" (customizable later)
    tmp["_breach"] = tmp[delay_col] >= 100

    sla_breach_rate = tmp["_breach"].mean() * 100 if len(tmp) > 0 else None

    sla_table = (
        tmp.groupby(priority_col, as_index=False)["_breach"].mean()
        .assign(**{"Breach Rate": lambda d: d["_breach"] * 100})
        .drop(columns=["_breach"])
        .sort_values("Breach Rate", ascending=False)
    )

if sla_breach_rate is None:
    empty_state(
        "Not enough data to estimate SLA risk.",
        "è³‡æ–™ä¸è¶³ä»¥æ¨ä¼° SLA é¢¨éšªã€‚",
        tips=[
            tx("Need Priority and Delay columns.", "éœ€è¦ Priority èˆ‡ Delay æ¬„ä½ã€‚"),
        ],
    )
else:
    st.write(f"**{tx('SLA Breach Rate', 'SLA é•è¦ç‡')}ï¼š{sla_breach_rate:.1f}%**")
    st.dataframe(sla_table, use_container_width=True)

st.markdown("</div>", unsafe_allow_html=True)

# =========================
# SECTION: Root Cause Breakdown
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Root Cause Breakdown",
    "æ ¹å› åˆ†é¡",
    "Understand what types of issues drive delays and risk.",
    "ç†è§£å“ªäº›é¡å‹çš„å•é¡Œæœ€å¸¸é€ æˆå»¶èª¤èˆ‡é¢¨éšªã€‚",
)

if not (root_cause_col and root_cause_col in df.columns):
    empty_state(
        "Root cause category is missing. This section will stay empty until the column exists.",
        "ç¼ºå°‘æ ¹å› åˆ†é¡æ¬„ä½ã€‚éœ€è¦æœ‰è©²æ¬„ä½æ­¤å€å¡Šæ‰æœƒé¡¯ç¤ºã€‚",
        tips=[
            tx("Add Root_Cause column to the CSV.", "è«‹åœ¨ CSV åŠ ä¸Š Root_Cause æ¬„ä½ã€‚"),
        ],
    )
else:
    rc = df[root_cause_col].dropna().astype(str)
    if rc.empty:
        empty_state(
            "Root cause column exists but has no usable values.",
            "æ ¹å› æ¬„ä½å­˜åœ¨ä½†ç›®å‰æ²’æœ‰å¯ç”¨å…§å®¹ã€‚",
            tips=[
                tx("Fill in at least some root cause categories.", "è«‹å¡«å…¥è‡³å°‘éƒ¨åˆ†æ ¹å› åˆ†é¡å…§å®¹ã€‚"),
            ],
        )
    else:
        rc_df = rc.value_counts().rename_axis("Root Cause").reset_index(name="Count")
        fig = px.pie(rc_df, names="Root Cause", values="Count", title=tx("Root Cause Distribution", "æ ¹å› åˆ†ä½ˆ"))
        st.plotly_chart(fig, use_container_width=True)

st.markdown("</div>", unsafe_allow_html=True)

# =========================
# SECTION: Blocked Details
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Blocked Details",
    "é˜»å¡å·¥å–®æ˜ç´°",
    "List tickets currently blocked and why they cannot move forward.",
    "åˆ—å‡ºç›®å‰è¢«å¡ä½çš„å·¥å–®èˆ‡å¡ä½åŸå› ã€‚",
)

blocked_df = pd.DataFrame()
if status_col and status_col in df.columns:
    blocked_df = df[df[status_col].astype(str).str.lower().eq("blocked")].copy()

if blocked_df.empty:
    empty_state(
        "No blocked tickets found in the current dataset.",
        "ç›®å‰è³‡æ–™ä¸­æ²’æœ‰ç‹€æ…‹ç‚º Blocked çš„å·¥å–®ã€‚",
        tips=[
            tx("If you expect blocked tickets, verify Status_Current values.", "å¦‚æœä½ é æœŸæœ‰é˜»å¡å·¥å–®ï¼Œè«‹ç¢ºèª Status_Current çš„å€¼ã€‚"),
        ],
    )
else:
    show_cols = []
    for c in [issue_key_col, summary_col, priority_col, role_col, assignee_col, blocked_reason_col]:
        if c and c in blocked_df.columns:
            show_cols.append(c)

    st.write(f"{tx('Blocked tickets', 'é˜»å¡å·¥å–®æ•¸')}ï¼š{len(blocked_df)}")
    st.dataframe(blocked_df[show_cols], use_container_width=True)

st.markdown("</div>", unsafe_allow_html=True)

# =========================
# SECTION: Stale Tickets
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Stale Tickets",
    "ä¹…æœªæ›´æ–°å·¥å–®",
    "Tickets not updated for a long time often indicate stalled work.",
    "é•·æ™‚é–“æœªæ›´æ–°å¸¸ä»£è¡¨æµç¨‹å¡ä½æˆ–ç¼ºå°‘æ¨é€²ã€‚",
)

stale_df = pd.DataFrame()

if last_updated_col and last_updated_col in df.columns:
    tmp = df.copy()
    tmp[last_updated_col] = to_datetime_safe(tmp[last_updated_col])
    now_utc = pd.Timestamp.now(tz=timezone.utc)
    tmp["_stale_days"] = (now_utc - tmp[last_updated_col]).dt.total_seconds() / 86400.0

    threshold = st.slider(tx("Stale threshold days", "ä¹…æœªæ›´æ–°é–€æª»å¤©æ•¸"), 1, 180, 30)

    exclude_done = st.checkbox(tx("Exclude Done tickets", "æ’é™¤ Done å·¥å–®"), value=True)

    stale_df = tmp.dropna(subset=["_stale_days"])
    stale_df = stale_df[stale_df["_stale_days"] >= threshold].sort_values("_stale_days", ascending=False)

    # Optional: exclude done
    if exclude_done and status_col and status_col in stale_df.columns:
        stale_df = stale_df[~stale_df[status_col].astype(str).str.lower().eq("done")]

    if stale_df.empty:
        empty_state(
            "No tickets exceed the threshold after applying filters, or timestamps are missing.",
            "å¥—ç”¨ç¯©é¸å¾Œæ²’æœ‰ç¬¦åˆé–€æª»çš„å·¥å–®ï¼Œæˆ–æ›´æ–°æ™‚é–“è³‡æ–™ä¸è¶³ã€‚",
            tips=[
                tx("Try lowering the threshold.", "å¯ä»¥å…ˆæŠŠé–€æª»èª¿å°ã€‚"),
                tx("Disable exclude Done to verify data exists.", "å¯å…ˆå–æ¶ˆæ’é™¤ Done ä¾†ç¢ºèªè³‡æ–™æ˜¯å¦å­˜åœ¨ã€‚"),
                tx("Check if Last_Updated_Date is parsable.", "ç¢ºèª Last_Updated_Date æ˜¯å¦å¯è§£æã€‚"),
            ],
        )
    else:
        cols = []
        for c in [issue_key_col, summary_col, priority_col, role_col, status_col, last_updated_col, "_stale_days"]:
            if c and c in stale_df.columns:
                cols.append(c)
        st.dataframe(stale_df[cols], use_container_width=True)
else:
    empty_state(
        "Not enough data to compute stale tickets. Missing Last_Updated_Date or invalid datetime format.",
        "ç„¡æ³•è¨ˆç®—ä¹…æœªæ›´æ–°å·¥å–®ã€‚å¯èƒ½ç¼ºå°‘ Last_Updated_Date æˆ–æ—¥æœŸæ ¼å¼ç„¡æ³•è§£æã€‚",
        tips=[
            tx("Add Last_Updated_Date to the export.", "è«‹åœ¨åŒ¯å‡ºæ™‚åŒ…å« Last_Updated_Dateã€‚"),
            tx("Use ISO datetime format.", "å»ºè­°ä½¿ç”¨ ISO æ—¥æœŸæ ¼å¼ã€‚"),
        ],
    )

st.markdown("</div>", unsafe_allow_html=True)

# =========================
# SECTION: Executive Summary
# =========================
st.markdown('<div class="section-card">', unsafe_allow_html=True)
card_title(
    "Executive Summary",
    "ç®¡ç†æ‘˜è¦",
    "One-click summary for reporting.",
    "ä¸€éµç”¢ç”Ÿå¯åŒ¯å ±çš„æ‘˜è¦ã€‚",
)

if st.button(tx("Generate Executive Report", "ç”¢ç”ŸåŒ¯å ±æ‘˜è¦")):
    # delay bottleneck
    delay_bottleneck = None
    if role_col and delay_col and role_col in df.columns and delay_col in df.columns:
        t = df[[role_col, delay_col]].copy()
        t[delay_col] = pd.to_numeric(t[delay_col], errors="coerce")
        t = t.dropna()
        if not t.empty:
            g = t.groupby(role_col)[delay_col].mean().sort_values(ascending=False)
            delay_bottleneck = (str(g.index[0]), float(g.iloc[0]))

    # queue bottleneck
    queue_bottleneck = None
    if status_col and status_entered_col and status_col in df.columns and status_entered_col in df.columns:
        t = df[[status_col, status_entered_col]].copy()
        t[status_entered_col] = to_datetime_safe(t[status_entered_col])
        now_utc = pd.Timestamp.now(tz=timezone.utc)
        t["_queue_days"] = (now_utc - t[status_entered_col]).dt.total_seconds() / 86400.0
        t = t.dropna(subset=[status_col, "_queue_days"])
        if not t.empty:
            g = t.groupby(status_col)["_queue_days"].mean().sort_values(ascending=False)
            queue_bottleneck = (str(g.index[0]), float(g.iloc[0]))

    # primary root cause
    primary_root_cause = None
    if root_cause_col and root_cause_col in df.columns:
        r = df[root_cause_col].dropna().astype(str)
        if not r.empty:
            primary_root_cause = r.value_counts().index[0]

    st.markdown(f"**{tx('Summary', 'æ‘˜è¦')}**")
    bullets = []
    if delay_bottleneck:
        bullets.append(tx(
            f"Delay bottleneck: {delay_bottleneck[0]} with average delay {delay_bottleneck[1]:.1f}%",
            f"å»¶èª¤ç†±å€ï¼š{delay_bottleneck[0]} å¹³å‡å»¶èª¤ {delay_bottleneck[1]:.1f}%",
        ))
    if queue_bottleneck:
        bullets.append(tx(
            f"Queue bottleneck: {queue_bottleneck[0]} with average waiting {queue_bottleneck[1]:.1f} days",
            f"ç­‰å¾…ç†±å€ï¼š{queue_bottleneck[0]} å¹³å‡ç­‰å¾… {queue_bottleneck[1]:.1f} å¤©",
        ))
    if sla_breach_rate is not None:
        bullets.append(tx(
            f"SLA risk: estimated breach rate {sla_breach_rate:.1f}%",
            f"SLA é¢¨éšªï¼šæ¨ä¼°é•è¦ç‡ {sla_breach_rate:.1f}%",
        ))
    if primary_root_cause:
        bullets.append(tx(
            f"Primary root cause: {primary_root_cause}",
            f"ä¸»è¦æ ¹å› ï¼š{primary_root_cause}",
        ))

    if not bullets:
        empty_state(
            "Not enough signals to generate a meaningful summary yet.",
            "ç›®å‰å¯ç”¨è¨Šè™Ÿä¸è¶³ï¼Œæš«æ™‚ç„¡æ³•ç”¢å‡ºå…·é«”æ‘˜è¦ã€‚",
            tips=[
                tx("Add Delay, Status dates, or Root Cause columns.", "å»ºè­°è£œå…… Delayã€ç‹€æ…‹æ—¥æœŸã€æ ¹å› æ¬„ä½ã€‚"),
            ],
        )
    else:
        for b in bullets:
            st.write("â€¢ " + b)

st.markdown("</div>", unsafe_allow_html=True)


